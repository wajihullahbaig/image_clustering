# Video clustering
Finding keyframes in video using image features and clustering.
Using this code you can create high lights of a video. like showing keyframes as GIFs to a user while the
user hovers the mouse over an icon.

## Video highlights
![GIF](movie.gif)

Some resources followed to code the project are as follows;

Input video used [video](https://sample-videos.com/video321/mp4/480/big_buck_bunny_480p_30mb.mp4)

Local Binary Pattern Descriptor[lbp descriptor](https://pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/)

Medium article [hog descriptor](https://medium.com/@dnemutlu/hog-feature-descriptor-263313c3b40d)

Python Code for HOG [hog descriptor](https://medium.com/@dnemutlu/hog-feature-descriptor-263313c3b40d)

Python implementation code for HoG[Hog Descriptor](https://builtin.com/articles/histogram-of-oriented-gradients#:~:text=Histogram%20of%20oriented%20gradients%20(HOG)%20is%20a%20feature%20descriptor%20like,the%20purpose%20of%20object%20detection.)

How Kmeans clustering works [kmeans clustering](https://www.statology.org/k-means-clustering-in-python/)

Finding optimal K using Kneed Algorithm[kneed algorithm](https://github.com/arvkevi/kneed)

# Notes Generated by Youtube Notes Generator

Full video [Youtube Video](https://www.youtube.com/watch?v=8f4oRcSnfbI)

Notes generator Repo [Youtube Notes Generator](https://github.com/di37/youtube-notes-generator)

Isham's Repos [Github profile](https://github.com/di37)

## Video Clustering Using Image Features

### Introduction

* The lecture focuses on **video clustering**, a technique for dividing videos into different segments using **image features**. 
* It covers:
    * **Basic insights** into video clustering.
    * How to **extract image features** from video frames.
    * How to **build a practical system** for clustering videos.
    * **Real-world applications** of video clustering.
    * **Code demo** using Python and OpenCV.

### Speaker Background

* The speaker has extensive experience in the tech industry, specifically in **computer vision, NLP, and machine learning**.
* He aims to deliver lectures on **classical machine learning techniques**, emphasizing **knowledge transfer and practical application**.

### Practical Applications of Video Clustering

* One practical use case is **shot detection**. 
    * This involves identifying transitions between different camera shots in a video, like a transition from a speaker to the audience.
    * This has applications in **video editing and content analysis**.
* While **machine learning and deep learning** are often used for shot detection, **simpler techniques** can also be effective.

### Understanding Image Features

* **Image features** are ways to describe the content within an image, enabling a computer to understand what it's looking at.
* This is a core concept in **computer vision**, which aims to enable computers to understand visual information.
* Image features can be categorized as:
    * **Holistic (global) features:** Analyze the entire image.
        * Output feature vector dimensions remain consistent regardless of input image size.
    * **Local features:** Focus on specific regions within the image.
        * Output features vary based on the image content.
        * Examples include: SIFT, SURF, ORB, BRISK.
* Image feature extraction generally focuses on:
    * **Edges:** Sharp transitions in pixel values.
    * **Gradients (orientation):** Direction and magnitude of changes in pixel values.
    * **Frequency:** Rarely used in this context.

### Local Binary Pattern (LBP) Features

* **LBP** is a simple local feature that describes the texture of an image.
* **Calculation:**
    1. Use a 3x3 neighborhood filter that slides over the image.
    2. Threshold the pixel values in each neighborhood using a user-defined threshold (e.g., 50).
    3. Assign a binary value (0 or 1) to each pixel based on the threshold.
    4. Convert the binary pattern into a decimal number using powers of 2.
    5. This number represents the LBP feature for that specific 3x3 window.
    6. Concatenate all the LBP features for all windows to create the final feature vector.

### Histogram of Oriented Gradients (HOG) Features

* **HOG** is a local feature that captures the distribution of gradient orientations in localized portions of an image.
* **Calculation:**
    1. Divide the image into blocks.
    2. For each block, apply a convolution operation to calculate the magnitude and gradient of pixel changes.
    3. Assign an orientation or gradient value to each block based on the calculated magnitudes and gradients.
* **Applications:** 
    * Object detection, particularly for detecting objects with distinct shapes (e.g., humans, cars).
    * The visualization of HOG features can reveal patterns related to object shapes within an image.

### Video Clustering Process

1. **Read the video:** Load the video file.
2. **Process frame-by-frame:** Iterate through each frame of the video.
3. **Extract features:** Compute the chosen image feature (LBP or HOG) for each frame.
4. **Normalize features:** Scale the features to a common range (e.g., 0 to 1).
5. **Accumulate features:** Gather all feature vectors.
6. **Find optimal K:** Determine the optimal number of clusters using techniques like the Elbow test.
7. **Create clusters:** Perform K-Means clustering on the feature vectors using the optimal K value.
8. **Pick independent frames:** Select one representative frame from each cluster.
9. **Create animated GIF:** Combine the selected frames into an animated GIF, creating a video highlight.

### Code Demo

* The demo uses **Python and OpenCV** for video processing and feature extraction.
* Two classes are implemented: one for **LBP features** and one for **HOG features**.
* Both classes inherit from a base class with an abstract `compute` method, ensuring consistent functionality.
* The code includes **type hinting for clarity**.
* The demo uses **PCA (Principal Component Analysis)** to reduce the dimensionality of the feature vectors for visualization purposes.
* The speaker prefers using **Spyder IDE** over Jupyter notebooks. 

### Q&A Session

* **Q: Can we incorporate LLMs (Large Language Models) into the pipeline to increase efficiency?**
    * **A:**  LLMs, particularly multi-modal LLMs, can be used for clustering and summarization of video content based on both visual and textual information. However, this lecture focuses on techniques that don't rely on the computational power of LLMs, exploring alternative approaches.
* **Q: What's your opinion on Meta's Segment Anything Model (SAM)?**
    * **A:** While SAM claims to be a general-purpose segmentation model, its performance on data outside its training domain needs to be thoroughly tested and evaluated. The speaker mentioned a research paper where SAM failed significantly when tested on MRI brain images, suggesting limitations in its generalization abilities. He recommends testing SAM on diverse datasets and carefully analyzing its performance before drawing conclusions.

### Concluding Remarks

* The lecture provided a comprehensive overview of video clustering using image features, covering both theoretical concepts and practical implementation.
* The speaker encouraged attendees to explore the provided code and resources, and to consider expanding the project by incorporating deep learning techniques. 
* He emphasized the importance of validating the claims made about AI models and testing them on diverse datasets to understand their true capabilities and limitations. 
